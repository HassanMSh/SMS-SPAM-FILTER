{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:07:05.286904Z",
          "start_time": "2022-12-25T20:07:02.701249Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5kGlupL9uwV",
        "outputId": "65bff14c-5491-4f60-8421-c9987a2ce5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.8/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from operator import index\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "!pip install langdetect\n",
        "import langdetect as detect\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Download necessary data for natural language processing tasks\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access data\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kt-UCdgQeOZ",
        "outputId": "4ab5728c-70a1-4850-87fe-4ac640ecb675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:07:09.930989Z",
          "start_time": "2022-12-25T20:07:05.291907Z"
        },
        "id": "2a5shdYT9uwa"
      },
      "outputs": [],
      "source": [
        "# Read in spam data from CSV file\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Training/spam.csv',\n",
        "                 sep=',', header=0, on_bad_lines='skip', encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:07:10.008120Z",
          "start_time": "2022-12-25T20:07:09.932996Z"
        },
        "id": "mXdrERRz9uwa"
      },
      "outputs": [],
      "source": [
        "# Drop any \"Unnamed\" columns\n",
        "\n",
        "unnamed_cols = df.columns[df.columns.str.contains(\"Unnamed\")]\n",
        "df.drop(columns=unnamed_cols, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:09:32.716710Z",
          "start_time": "2022-12-25T20:07:10.011088Z"
        },
        "id": "GM6B8gZY9uwb"
      },
      "outputs": [],
      "source": [
        "# Define regular expression variables to remove from SMS messages\n",
        "\n",
        "reg_vars = ['http\\S+', 'www\\S+', 'https\\S+', '\\W\\s+', '\\d+', '\\t+', '\\d+', '\\-+', '\\\\+', '\\/+', '\\\"+', '\\#+', '\\++', '\\@+', '\\$+', '\\%+', '\\^+', '\\&+', '\\*+', '\\(+', '\\)+', '\\[+', '\\]+', '\\{+', '\\}+', '\\|+', '\\;+', '\\:+', '\\<+', '\\>+', '\\?+', '\\,+', '\\.+', '\\=+', '\\_+', '\\~+', '\\`+', '\\s+']\n",
        "\n",
        "df.replace(reg_vars, ' ', regex=True, inplace=True)\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df.replace('', np.nan, inplace=True)\n",
        "\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:09:32.810714Z",
          "start_time": "2022-12-25T20:09:32.718712Z"
        },
        "id": "fcyyilOf9uwc"
      },
      "outputs": [],
      "source": [
        "# Remove rows with non-ASCII characters from the dataframe\n",
        "\n",
        "df = df[df['v2'].map(lambda x: x.isascii())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:17.965231Z",
          "start_time": "2022-12-25T20:09:32.818716Z"
        },
        "id": "ToTOSXe_9uwd"
      },
      "outputs": [],
      "source": [
        "# Drop non-English rows from the dataframe\n",
        "\n",
        "for i in range(len(df)):\n",
        "    try:\n",
        "        ['v2'][i] = detect.detect(df['v2'][i])\n",
        "        if df['v2'][i] != 'en':\n",
        "            df.drop(i, inplace=True, index=False)\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:18.042932Z",
          "start_time": "2022-12-25T20:10:17.968160Z"
        },
        "id": "x3jZO2Bx9uwf"
      },
      "outputs": [],
      "source": [
        "# Convert all the text data into lowercase\n",
        "\n",
        "df['v2'] = df['v2'].astype(str).str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:18.073317Z",
          "start_time": "2022-12-25T20:10:18.046828Z"
        },
        "id": "nyeK_kC19uwf"
      },
      "outputs": [],
      "source": [
        "# Retrieve a list of English stop words and assign it to a var\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:29.220261Z",
          "start_time": "2022-12-25T20:10:18.075205Z"
        },
        "id": "g5KfAca59uwg"
      },
      "outputs": [],
      "source": [
        "# Tokenize the SMS messages in the dataframe\n",
        "\n",
        "df['TokenSMS'] = df.apply(lambda column: nltk.word_tokenize(column['v2']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['TokenSMS'].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXtFK10dF5NP",
        "outputId": "06a38045-43e3-4148-fadd-c323970f2ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [go, until, jurong, point, crazy, available, o...\n",
              "1                       [ok, lar, joking, wif, u, oni]\n",
              "Name: TokenSMS, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:32.232336Z",
          "start_time": "2022-12-25T20:10:29.224271Z"
        },
        "id": "FKD0_cv39uwh"
      },
      "outputs": [],
      "source": [
        "# Create a column containing the Tokenized words without the stopwords\n",
        "\n",
        "df['StopTokenSMS'] = df['TokenSMS'].apply(lambda x: [item for item in x if item not in stopwords])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:32.404006Z",
          "start_time": "2022-12-25T20:10:32.234348Z"
        },
        "id": "WgVolA7h9uwh"
      },
      "outputs": [],
      "source": [
        "# Create a coolumn containting the StopTokenSMS text with words less than 2 characters\n",
        "\n",
        "df['LengthTokenSMS'] = df['StopTokenSMS'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:35.396210Z",
          "start_time": "2022-12-25T20:10:35.383872Z"
        },
        "id": "HzQUiA0C9uwj"
      },
      "outputs": [],
      "source": [
        "# Instantiate and the assigne a variable to the WordNetLemmatizer class\n",
        "\n",
        "wordnet_lem = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-25T20:10:37.374898Z",
          "start_time": "2022-12-25T20:10:35.399067Z"
        },
        "id": "FpcWO3xl9uwj"
      },
      "outputs": [],
      "source": [
        "# Create a new column which contains the lemmatized words\n",
        "\n",
        "df['LemTokenSMS'] = df['LengthTokenSMS'].apply(wordnet_lem.lemmatize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean all dataframes again\n",
        "\n",
        "reg_vars = ['http\\S+', 'www\\S+', 'https\\S+', '\\W\\s+', '\\d+', '\\t+', '\\d+', '\\-+', '\\\\+', '\\/+', '\\\"+', '\\#+', '\\++', '\\@+', '\\$+', '\\%+', '\\^+', '\\&+', '\\*+', '\\(+', '\\)+', '\\[+', '\\]+', '\\{+', '\\}+', '\\|+', '\\;+', '\\:+', '\\<+', '\\>+', '\\?+', '\\,+', '\\.+', '\\=+', '\\_+', '\\~+', '\\`+', '\\s+']\n",
        "\n",
        "df.replace(reg_vars, ' ', regex=True, inplace=True)\n",
        "\n",
        "df.replace('', np.nan, inplace=True)\n",
        "\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "SSsVRl9_5YR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a CountVectorizer object\n",
        "\n",
        "cv = CountVectorizer()"
      ],
      "metadata": {
        "id": "xAh3RuHoDMRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit_transform the data to a numpy array\n",
        "\n",
        "x = cv.fit_transform(df['LemTokenSMS']).toarray()"
      ],
      "metadata": {
        "id": "-Z-9ZRnzDNxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2uaFiMNDmqH",
        "outputId": "76896315-953e-43bf-9fec-4f9133aaabbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4672, 6869)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'spam' with 1 and 'ham' with 0\n",
        "df['v1'] = df['v1'].replace({'spam': 1, 'ham': 0})"
      ],
      "metadata": {
        "id": "EVlfyZk9DxR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the labels in  y\n",
        "\n",
        "y = df['v1'].values"
      ],
      "metadata": {
        "id": "5xLo2KnMDnnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xchr3u5xDvpD",
        "outputId": "4006f4f9-5980-4d2d-a96f-512366630179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4672,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert y to to int type\n",
        "\n",
        "y = y.astype('int')"
      ],
      "metadata": {
        "id": "cOIgfPAgE5tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and testing set\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "ShSomIqXE_Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM4w7T3EFAUa",
        "outputId": "4a77eece-f22f-4ecd-a7a3-2e674494ac94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.astype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNPp3lVsFHFn",
        "outputId": "aa9752d4-28fd-443d-96c1-433b26b09002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function ndarray.astype>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a MultinomialNB objec\n",
        "\n",
        "mnb=MultinomialNB()"
      ],
      "metadata": {
        "id": "ZURwmk7mFM1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the classifier and making predictions on the test data\n",
        "\n",
        "mnb.fit(x_train,y_train)\n",
        "y_pred=mnb.predict(x_test)\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UOH4RZZFOwr",
        "outputId": "614fd7bc-1049-4436-e53b-a833d75fb31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9689839572192513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model to a file\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(mnb, file)\n",
        "\n",
        "# Save the model to a file\n",
        "with open('cv.pkl', 'wb') as file:\n",
        "    pickle.dump(cv, file)"
      ],
      "metadata": {
        "id": "dsDolCvTGYjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('model.pkl')\n",
        "files.download('cv.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ejbw43F34HlD",
        "outputId": "77488803-7ad5-4a45-b6df-98bda7c1f114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_62928a3e-bc45-4992-b346-35844e080104\", \"model.pkl\", 220409)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e01cef26-448e-45d3-9abd-bc95195f3b13\", \"cv.pkl\", 83816)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a preprocessing function to process new text\n",
        "\n",
        "def clean_dataframe(df):\n",
        "    reg_vars = ['http\\S+', 'www\\S+', 'https\\S+', '\\W\\s+', '\\d+', '\\t+', '\\d+', '\\-+', '\\\\+', '\\/+', '\\\"+', '\\#+', '\\++', '\\@+', '\\$+', '\\%+', '\\^+', '\\&+', '\\*+', '\\(+', '\\)+', '\\[+', '\\]+', '\\{+', '\\}+', '\\|+', '\\;+', '\\:+', '\\<+', '\\>+', '\\?+', '\\,+', '\\.+', '\\=+', '\\_+', '\\~+', '\\`+', '\\s+']\n",
        "    df['text'].replace(reg_vars, ' ', regex=True, inplace=True)\n",
        "    df['text'] = df['text'].astype(str).str.lower()\n",
        "    df['text'] = df.apply(lambda column: nltk.word_tokenize(column['text']), axis=1)\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
        "    df['text'] = df['text'].apply(wordnet_lem.lemmatize)\n"
      ],
      "metadata": {
        "id": "Z2kxpggAFhnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [{\"text\": \"Urgent dont miss news dun say so early hor... U c already then say lucky man\"}]\n",
        "\n",
        "ndf = pd.DataFrame(data)\n",
        "\n",
        "clean_dataframe(ndf)"
      ],
      "metadata": {
        "id": "T0G_tbwsLOrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newtext = cv.transform(ndf['text']).toarray()\n",
        "prediction = mnb.predict(newtext)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2bUkXdvLfzZ",
        "outputId": "9736a0f9-f0f6-4518-85f3-53ec24264681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "42px",
        "width": "160px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}